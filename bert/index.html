
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="The use of AI in medical diagnosis and treatment">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../bigfile/">
      
      <link rel="icon" href="../assets/mb.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.14">
    
    
      
        <title>BERT: Bidirectional Encoder Representations from Transformers - Research Blog</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.85bb2934.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.a6bdf11c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#bert-bidirectional-encoder-representations-from-transformers" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Research Blog" class="md-header__button md-logo" aria-label="Research Blog" data-md-component="logo">
      
  <img src="../assets/mb.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Research Blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              BERT: Bidirectional Encoder Representations from Transformers
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Research Blog" class="md-nav__button md-logo" aria-label="Research Blog" data-md-component="logo">
      
  <img src="../assets/mb.png" alt="logo">

    </a>
    Research Blog
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          BERT: Bidirectional Encoder Representations from Transformers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        BERT: Bidirectional Encoder Representations from Transformers
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    Overview
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-points" class="md-nav__link">
    Key Points
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#discussion" class="md-nav__link">
    Discussion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-attention" class="md-nav__link">
    Self-attention
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../bigfile/" class="md-nav__link">
        Order of Magnitude Faster Image Loading in Pytorch
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../broadcasting/" class="md-nav__link">
        Broadcasting in PyTorch
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../cnn_v_transformer/" class="md-nav__link">
        Transformers vs. Convolutional Neural Networks
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../consistency_encoder/" class="md-nav__link">
        Consistency encoder
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../goleman/" class="md-nav__link">
        Book Review - What Makes a Leader
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../healthcare/" class="md-nav__link">
        GenAI in Healthcare
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../hessenberg/" class="md-nav__link">
        Sparse Matrices
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../labeling/" class="md-nav__link">
        Cutting Labeling Costs by 90%
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../layernorm/" class="md-nav__link">
        Layernorm
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../multihead_attention/" class="md-nav__link">
        Exploring Tensor Broadcasting in MultiHead Attention
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../transformer/" class="md-nav__link">
        Toy GPT example
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    Overview
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-points" class="md-nav__link">
    Key Points
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#discussion" class="md-nav__link">
    Discussion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-attention" class="md-nav__link">
    Self-attention
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="bert-bidirectional-encoder-representations-from-transformers">BERT: Bidirectional Encoder Representations from Transformers</h1>
<h2 id="overview">Overview</h2>
<p>BERT, or Bidirectional Encoder Representations from Transformers, is a groundbreaking NLP model developed by Google. One of the key advantages of BERT is its ability to understand context and meaning in <strong>both</strong> directions, forward and backward, through a self-supervised training process.</p>
<h2 id="key-points">Key Points</h2>
<ul>
<li>
<p>BERT achieves this advanced understanding of language by pre-training on massive amounts of unlabeled text data from sources like Wikipedia and books corpus. This allows it to capture the context and relationships between words in a sentence, rather than focusing solely on individual word meanings.</p>
</li>
<li>
<p>The model is based on <strong>Transformer</strong> architecture, which was originally proposed for machine translation tasks. BERT uses a self-attention mechanism, which allows it to consider all possible word relationships and generate highly accurate contextualized representations of words. This makes the model more robust in various language understanding tasks, such as question answering, sentiment analysis, and natural language inference.</p>
</li>
<li>
<p>BERT's performance has significantly outperformed previous state-of-the-art models on various benchmarking datasets, leading to its widespread adoption among researchers and developers. Due to this success, Google open-sourced BERT, making it accessible for further development and experimentation in the research community.</p>
</li>
<li>
<p>BERT is a powerful and innovative natural language processing model that has revolutionized the field with its ability to understand context and meaning in both forward and backward directions. Its impact is evident through its continued use by researchers even years after its initial release.</p>
</li>
</ul>
<h2 id="discussion">Discussion</h2>
<p>One of the key features of BERT is its ability to capture the context and relationships between words in a sentence, rather than focusing solely on individual word meanings. This is achieved through a process of pre-training on massive amounts of unlabeled text data from sources like Wikipedia and books corpus. By analyzing this data, BERT is able to learn the patterns and relationships between words, allowing it to generate contextualized representations of words.</p>
<p>For example, consider the sentence "The cat sat on the mat." Without any context, the word "cat" could refer to any type of feline, but with the context of the sentence, we know that it is referring to a specific cat that is sitting on a mat. BERT is able to capture this context and relationship between the words in the sentence, allowing it to generate a more accurate representation of the sentence as a whole.</p>
<p>In contrast, traditional word-based models such as word2vec or GloVe, which only consider the individual word meanings, would generate embeddings for "cat" and "mat" that do not capture the relationship between them in the context of the sentence. This can lead to less accurate predictions and poorer performance on tasks such as language translation or sentiment analysis.
BERT's ability to capture context and relationships between words is a key factor in its success and has led to significant improvements across a wide range of NLP tasks.</p>
<h2 id="self-attention">Self-attention</h2>
<p>Self-attention is a mechanism in deep learning that allows a model to attend to different parts of an input sequence when making predictions. It is a way for the model to weigh the importance of different features in the input and use that information to make more accurate predictions.</p>
<p>Intuitively, self-attention can be thought of as a way for the model to "focus" on certain parts of the input when making predictions. For example, if the input is a sequence of words, self-attention can allow the model to focus on certain words that are more important for making a prediction, rather than considering the entire sequence equally.</p>
<p>Self-attention is implemented using a set of learnable weights that are used to compute a set of attention scores. These attention scores represent the degree to which each feature in the input is important for making a prediction. The attention scores are then used to weight the input features, so that more important features are given more weight and less important features are given less weight. This is especially useful for tasks like machine translation, where the model needs to understand the context of an entire sentence rather than individual words. Self-attention has also been used in computer vision tasks, where it can help the model to focus on certain parts of an image that are more important for making a prediction.</p>
<p>Mathematically, Self-Attention can be represented as:</p>
<p>
<script type="math/tex; mode=display"> softmax(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}})</script>
</p>
<p>where Q, K, V are learnable matrices for projections of queries (Q), keys (K) and values (V). </p>
<p>The <strong>attention</strong> score between a query and each key in the sequence is calculated using a dot product, and then normalized through the softmax function to get the weight for each value vector.</p>
<p>Let's break it down step-by-step: </p>
<ol>
<li>Calculate Query Matrix:</li>
</ol>
<p>
<script type="math/tex; mode=display">\mathbf{Q} = \mathbf{x}\mathbf{W}_q</script>
</p>
<p>where x is the input sequence and W_q is a weight matrix for queries.</p>
<ol>
<li>Calculate Key Matrix:</li>
</ol>
<p>
<script type="math/tex; mode=display">\mathbf{K} = \mathbf{x}\mathbf{W}_k</script>
</p>
<p>where W_k is a weight matrix for keys.</p>
<ol>
<li>Calculate Value Matrix:</li>
</ol>
<p>
<script type="math/tex; mode=display">\mathbf{V} = \mathbf{x}\mathbf{W}_v</script>
</p>
<p>where W_v is a weight matrix for values.</p>
<p>We have now taken input x and compute 3 distinct linear transformations.</p>
<ol>
<li>Dot Product Attention:</li>
</ol>
<p>Attention scores are calculated as the dot product between Q and K, followed by a softmax function to obtain the weights for each value vector:</p>
<p>
<script type="math/tex; mode=display">\mathbf{A} = softmax(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}})</script>
</p>
<p>where d_k is the dimensionality of key vectors.</p>
<ol>
<li>Weighted Sum of Value Matrix:</li>
</ol>
<p>Finally, the output of the self-attention mechanism is obtained by taking a weighted sum of value vectors using attention scores from step 4:</p>
<p>
<script type="math/tex; mode=display">\mathbf{O} = \mathbf{V}\mathbf{A}</script>
</p>
<p>Self-Attention is a powerful technique that allows models to capture context and relationships between parts of an input sequence. The mathematical implementation involves
1. Projecting inputs as queries, keys, and values through learnable weight matrices. 
2. Dot product attention mechanism 
3. Weighted sum over value vectors.</p>
<h2 id="summary">Summary</h2>
<p>BERT is particularly useful for NLP tasks where context is crucial. For example, in question answering, BERT can understand the context of a question and generate a accurate response, even when the question is phrased in a way that differs from the original text. Similarly, in sentiment analysis tasks, BERT can accurately identify the sentiment of a sentence, even when the sentiment is expressed in a subtle or nuanced way. BERT is highly versatile and can be adapted to a wide range of NLP tasks -- and has significantly impacted the way we approach language understanding in machine learning.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["content.code.copy"], "search": "../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.b4d07000.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>